# Automatic Image Storage System

This document describes the implementation of the automatic image storage system for Replicate-generated images.

## Problem Solved

Previously, images generated by Replicate were stored with temporary URLs that expire after 1 hour, leading to broken images in the application. The new system automatically downloads these images and stores them permanently in AWS S3.

## Architecture Overview

```
Replicate → Generate Images → Webhook → Auto Storage Service → AWS S3 → Permanent URLs
```

### Components

1. **Auto Image Storage Service** (`src/lib/services/auto-image-storage.ts`)
   - Downloads images from Replicate URLs
   - Uploads to AWS S3 with proper permissions
   - Generates permanent public URLs
   - Handles error recovery and validation

2. **API Endpoint** (`src/app/api/auto-storage/route.ts`)
   - RESTful endpoint for manual image processing
   - Validation and database updates
   - Image accessibility verification

3. **Webhook Integration** (`src/app/api/webhooks/generation/route.ts`)
   - Automatic processing when generations complete
   - Fallback to legacy storage system
   - Real-time status updates

4. **Configuration Script** (`scripts/configure-s3-bucket.js`)
   - Sets up S3 bucket permissions and CORS
   - Configures lifecycle policies
   - Verifies configuration

## Setup Instructions

### 1. Configure AWS S3 Bucket

Run the configuration script to set up your S3 bucket:

```bash
node scripts/configure-s3-bucket.js
```

This script will:
- Configure CORS for web access
- Set bucket policy for public read access
- Set up lifecycle rules for cost optimization
- Verify the configuration

### 2. Environment Variables

Ensure these environment variables are set in `.env.local`:

```env
# AWS Configuration
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_REGION=us-east-1
AWS_S3_BUCKET=ensaio-fotos-prod

# Optional: CloudFront CDN
AWS_CLOUDFRONT_URL=https://your-distribution.cloudfront.net
```

### 3. Test the System

Run the test script to verify everything is working:

```bash
node scripts/test-image-storage.js
```

## How It Works

### Automatic Processing (Default)

When a generation completes via webhook:

1. **Replicate Webhook** → Generation completed with temporary URLs
2. **Auto Storage Service** → Downloads images and uploads to S3
3. **Database Update** → Updates generation record with permanent URLs
4. **Fallback** → If auto-storage fails, falls back to legacy system
5. **Final Fallback** → If all storage fails, keeps temporary URLs with warning

### Manual Processing (API)

You can also process images manually via API:

```bash
POST /api/auto-storage
Content-Type: application/json

{
  "urls": ["https://replicate.delivery/pbxt/abc123.jpg"],
  "generationId": "generation-id",
  "userId": "user-id",
  "modelId": "model-id"
}
```

### File Organization

Images are stored with the following structure in S3:

```
bucket/
└── generated/
    └── cmf/
        ├── generation-id-1-abcd1234.jpg
        ├── generation-id-2-efgh5678.jpg
        └── generation-id-3-ijkl9012.jpg
```

## Features

### Reliability
- **Dual Storage System**: Auto-storage with legacy fallback
- **Error Recovery**: Graceful handling of failures
- **Validation**: Verifies images are accessible after upload
- **Retry Logic**: Built-in retry for transient failures

### Performance
- **Concurrent Processing**: Processes multiple images in parallel
- **Optimized Downloads**: 30-second timeout with proper headers
- **CDN Support**: CloudFront integration for faster delivery
- **Caching**: 1-year cache headers for optimal performance

### Security
- **Public Read Access**: Only for generated images (not training data)
- **HTTPS Only**: All URLs use HTTPS
- **Server-side Encryption**: AES256 encryption at rest
- **CORS Configuration**: Properly configured for web access

### Cost Optimization
- **Lifecycle Rules**: Automatic archiving to reduce storage costs
- **Cleanup Policies**: Removes incomplete multipart uploads
- **Standard IA**: Moves old images to cheaper storage class
- **Glacier**: Long-term archival for very old images

## Configuration Details

### S3 Bucket Policy

The bucket policy allows public read access only to generated images:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": "*",
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::ensaio-fotos-prod/generated/*"
    }
  ]
}
```

### CORS Configuration

CORS is configured to allow web access from your domains:

```json
{
  "CORSRules": [
    {
      "AllowedHeaders": ["*"],
      "AllowedMethods": ["GET", "HEAD"],
      "AllowedOrigins": ["*"],
      "ExposeHeaders": ["ETag"],
      "MaxAgeSeconds": 3600
    }
  ]
}
```

### Lifecycle Policy

Automatically manages costs by transitioning old files:

- **Incomplete uploads**: Deleted after 1 day
- **Generated images**: Move to Standard-IA after 90 days
- **Old images**: Move to Glacier after 365 days

## Monitoring and Debugging

### Logs

The system provides detailed logging:

```bash
# Check generation webhook logs
tail -f logs/generation-webhook.log

# Check auto-storage service logs
tail -f logs/auto-storage.log
```

### Health Check

Monitor the system health:

```bash
GET /api/auto-storage?generationId=generation-id
```

### Common Issues

1. **Access Denied Errors**
   - Check AWS credentials
   - Verify bucket policy
   - Ensure CORS is configured

2. **Image Not Found**
   - Verify S3 object exists
   - Check public read permissions
   - Test direct S3 URL access

3. **Slow Performance**
   - Enable CloudFront CDN
   - Check network connectivity
   - Monitor S3 transfer rates

## Migration Notes

### Existing Images

This system only processes new generations automatically. Existing images with temporary URLs will remain unchanged unless manually processed.

### Database Schema

No database changes are required. The system uses existing fields:
- `imageUrls`: Array of permanent image URLs
- `thumbnailUrls`: Array of thumbnail URLs
- `metadata`: Additional storage information

### Backward Compatibility

The system is fully backward compatible:
- Legacy storage system remains as fallback
- Existing API endpoints unchanged
- No breaking changes to frontend

## Troubleshooting

### Test Commands

```bash
# Test S3 configuration
node scripts/configure-s3-bucket.js

# Test image processing
node scripts/test-image-storage.js

# Manual API test
curl -X POST http://localhost:3000/api/auto-storage \
  -H "Content-Type: application/json" \
  -d '{"urls":["test-url"],"generationId":"test"}'
```

### Debug Mode

Enable debug logging by setting:

```env
DEBUG=auto-storage*
```

This will provide detailed logs of the image processing workflow.